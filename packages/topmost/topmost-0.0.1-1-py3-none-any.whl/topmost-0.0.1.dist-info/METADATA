Metadata-Version: 2.1
Name: topmost
Version: 0.0.1
Summary: Topmost: Neural Topic Modeling System Tookit
Home-page: https://github.com/bobxwu/
Author: Xiaobao Wu
Author-email: xiaobao002@e.ntu.edu.sg
License: Apache 2.0 License
Keywords: toolkit,topic model,neural topic model
Classifier: Intended Audience :: Education
Classifier: Programming Language :: Python :: 3
Classifier: Operating System :: MacOS :: MacOS X
Classifier: Operating System :: Microsoft :: Windows
Description-Content-Type: text/markdown

# TopMost: A Topic Modeling System Toolkit

TopMost provides a complete lifecycle of topic models, including dataset preprocessing, model training and evaluation.
It covers the most popular topic modeling scenarios, like static, dynamic, hierarchical, and cross-lingual topic modeling.

This is our demo paper of TopMost: [TopMost: A Topic Modeling System Toolkit]().  
This is our survey on neural topic models: [A Survey on Neural Topic Models: Methods, Applications, and Challenges](https://www.researchsquare.com/article/rs-3049182/latest.pdf).


- [TopMost: A Topic Modeling System Toolkit](#topmost-a-topic-modeling-system-toolkit)
  - [Introduction](#introduction)
    - [Topic Models](#topic-models)
  - [Usage](#usage)
    - [1. Install](#1-install)
    - [2. Preprocessing Datasets](#2-preprocessing-datasets)
    - [3. Train a model](#3-train-a-model)
    - [4. Evaluate](#4-evaluate)
    - [5. Test New Documents](#5-test-new-documents)
    - [6. Visualize](#6-visualize)
  - [Notice](#notice)
    - [Differences from original implementations](#differences-from-original-implementations)
  - [Contributors](#contributors)
  - [Disclaimer](#disclaimer)
  - [Acknowledgements](#acknowledgements)


## Introduction

### Topic Models

We provide the following fundamental and recent models:

<table>
<tbody>
<tr>
<td>Scenario</td>
<td>Model</td>
<td>Evaluation Metric</td>
<td>Datasets</td>
</tr>
<tr>
<td>Static Topic Models</td>
<td>
    <a href="">LDA</a><br/>
    <a href="">NMF</a><br/>
    <a href="https://arxiv.org/pdf/1703.01488">ProdLDA</a><br/>
    <a href="https://aclanthology.org/2021.findings-acl.15.pdf">DecTM</a><br/>
    <a href="https://aclanthology.org/2020.tacl-1.29.pdf">ETM</a><br/>
    <a href="https://arxiv.org/abs/2008.13537">NSTM</a><br/>
    <a href="">CTM</a><br/>
    <a href="https://aclanthology.org/2022.emnlp-main.176">TSCTM</a><br/>
    <a href="https://arxiv.org/pdf/2306.04217">ECRTM</a>
</td>
<td>
    TC<br/>
    TD<br/>
    Clustering<br/>
    Classification
</td>
<td>
    20NG<br/>
    IMDB<br/>
    NeurIPS<br/>
    ACL<br/>
    NYT<br/>
    Wikitext-103<br/>
</td>
</tr>
<tr>
<td>Hierarchical Topic Models</td>
<td>
    <a href="https://arxiv.org/abs/2210.10625">HyperMiner</a><br/>
    <a href="https://proceedings.mlr.press/v202/duan23c/duan23c.pdf">ProGBN</a>
</td>
<td>
    TC over levels<br/>
    TD over levels<br/>
    Clustering over levels<br/>
    Classification over levels
</td>
<td>
    20NG<br/>
    IMDB<br/>
    NeurIPS<br/>
    ACL<br/>
    NYT<br/>
    Wikitext-103<br/>
</td>
</tr>
<tr>
<td>Dynamic Topic Models</td>
<td>
    <a href="https://arxiv.org/abs/2012.01524">DETM</a>
</td>
<td>
    TC over time slices<br/>
    TD over time slices<br/>
    Clustering<br/>Classification
</td>
<td>
    NeurIPS<br/>
    ACL<br/>
    NYT<br/>
</td>
</tr>
<tr>
<td>Cross-lingual Topic Models</td>
<td>
    <a href="https://bobxwu.github.io/files/pub/NLPCC2020_Neural_Multilingual_Topic_Model.pdf">NMTM</a><br/>
    <a href="https://arxiv.org/abs/2304.03544">InfoCTM</a>
</td>
<td>
    TC (CNPMI)<br/>
    TD over languages<br/>
    Classification (Intra-lingual and Cross-lingual)
</td>
<td>
    ECNews<br/>
    Amazon Review<br/>
    Rakuten Amazon<br/>
</td>
</tr>
</tbody>
</table>

<!-- ### Datasets

We provide the following preprocessed datasets:


### Evaluation Metrics

We provide the following evaluation metrics: -->



1. Fix a bug in gensim.Coherencemodel.




## Usage

### 1. Install

Install topmost with `pip` as

```
pip install topmost
```


### 2. Preprocessing Datasets

TopMost can preprocess datasets for topic modeling in a standard way.
Here are the steps:

1. Prepare datasets.

    A dataset must include two files: `train.jsonlist` and `test.jsonlist`. Each contains a list of json, like

```json
  {"label": "rec.autos", "text": "WHAT car is this!?..."}
  {"label": "comp.sys.mac.hardware", "text": "A fair number of brave souls who upgraded their..."}
```

2. Preprocess datasets.

```python
  import topmost

  preprocessing = topmost.preprocessing.Preprocessing(stopwords_dir="...")
  preprocessing.parse(dataset_dir="...", label_name="label")
  preprocessing.save(output_dir="...")
```



### 3. Train a model

```python
import topmost

device = "cuda" # or "cpu"

# load a preprocessed dataset
dataset_handler = topmost.data.StaticDatasetHandler("20NG", device)
# create a model
model = topmost.models.ETM(vocab_size=dataset_handler.vocab_size, pretrained_WE=dataset_handler.pretrained_WE)
model = model.to(device)

# create a runner
runner = topmost.runners.StaticRunner(model, dataset_handler, epochs=2)
# train the model
runner.train()

```

### 4. Evaluate

```python
# evaluate
# get theta (doc-topic distributions)
train_theta, test_theta = runner.export_theta()

# get top words of topics
top_words = runner.export_top_words(num_top=15)

# evaluate clustering
results = topmost.evaluations.evaluate_clustering(test_theta, dataset_handler.test_labels)
print(results)

# evaluate classification
results = topmost.evaluations.evaluate_classification(train_theta, test_theta, dataset_handler.train_labels, dataset_handler.test_labels)
print(results)

# evaluate topic coherence

# evaluate topic diversity
TD = topmost.evaluations.compute_topic_diversity(top_words, _type="TD")
print(f"TD: {TD:.5f}")

```

### 5. Test New Documents

```python
# test new documents
import torch

new_texts = [
    "This is a new document about space, including words like space, satellite, launch, orbit.",
    "This is a new document about Microsoft Windows, including words like windows, files, dos."
]

parsed_new_texts, new_bow = preprocessing.parse(new_texts, vocab=dataset_handler.vocab)
new_theta = runner.test(torch.as_tensor(new_bow, device=device).float())
```

### 6. Visualize




## Notice

### Differences from original implementations

1. Oringal implementations may use different optmizer settings. For simplity and brevity, our package in default uses the same setting for different models.



## Contributors
<!-- ALL-CONTRIBUTORS-LIST:START - Do not remove or modify this section -->
<!-- prettier-ignore-start -->
<!-- markdownlint-disable -->
<table>
  <tbody>
    <tr>
      <td align="center" valign="top" width="120px">
          <a href="https://bobxwu.github.io/">
              <img src="https://bobxwu.github.io/img/figure.jpg" width="80px;" style="border-radius: 100%" alt="Xiaobao Wu"/>
              <br/>
              <sub><b>Xiaobao Wu</b></sub>
          </a>
      </td>
    </tr>
  </tbody>
</table>


<!-- ## Citation

If you are interested in our work and plan to use it, please cite as -->


## Disclaimer

This library includes some datasets for demostration.
If you are a dataset owner who wants to exclude your dataset from this library,
please contact [Xiaobao Wu](xiaobao002@e.ntu.edu.sg).

## Acknowledgements

- If you want to add any models to this package, we welcome your pull requests.
- If you encounter any problem, please either directly contact [Xiaobao Wu](xiaobao002@e.ntu.edu.sg) or leave an issue in the GitHub repo.
