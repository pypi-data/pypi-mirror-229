Metadata-Version: 2.1
Name: few-shot-priming
Version: 0.0.554
Summary: Analyzing priming effects in a few shot setting environment
Home-page: https://gitlab.uni-hannover.de/y.ajjour/few-shot-priming
Author: Yamen Ajjour
Author-email: yajjour@hotmail.com
Classifier: Programming Language :: Python :: 3
Classifier: License :: OSI Approved :: MIT License
Classifier: Operating System :: OS Independent
Description-Content-Type: text/markdown
Requires-Dist: transformers (>=4.26.1)
Requires-Dist: pandas
Requires-Dist: openprompt
Requires-Dist: scikit-learn
Requires-Dist: torch
Requires-Dist: pyyaml
Requires-Dist: wandb
Requires-Dist: debater-python-api
Requires-Dist: sentencepiece

# Analyzing Priming Effect in Prompt-based learning

How does priming affect prompt-based learing?
This project aims at analyzing this effect in stance classification.
We train a stance classifier on the ibm stance classification dataset by
fine-tuning a GPT-2 model with a prompt and analzing how does the selection
of the few shots used in the prompt affect the performance of the model.
Our main assumption is that the examples chosen should be chosen in a diverse manner with regard topic.
1) To evaluate the prompt-fine-tuning, run the following command
* Hyperparamter optimization
```
python scripts/run_prompt_fine_tuning.py --validate --optimize 
```

* Best Hyperparameters
```
python scripts/run_prompt_fine_tuning.py --validate --optimize 
``` 
2) To evaluate the in-context (prompt) setup run
```
python scripts/run_prompt_fine_tuning.py --validate --optimize 
```
3) To evaluate DeBERTa (a normal classifier) with all hyperparameters, run the following
```
python scripts/optimize_baseline.py 
```
The results of the experiments will be logged to your home directory.
The parameters can be saved in [config.yaml](../blob/maser/config.yaml)
